{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Check PyTorch version\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Torch Tensors\n",
    "See https://pytorch.org/docs/stable/tensors.html on tensor types.\n",
    "The default tensor is 32 bit. If tensor is another dtpe, this will be shown when the tensor is printed. Frequently 16 bit will be enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.0779e+04, 4.5602e-41],\n",
      "        [1.0779e+04, 4.5602e-41],\n",
      "        [4.1486e-08, 1.3556e-19]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create empty tensor (32 bit float)\n",
    "a = torch.empty(3,2)\n",
    "print (a, a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create a zero tensor (32 bit float, by default)\n",
    "a = torch.zeros(4, 3)\n",
    "print (a, a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create a ones tensor (32 bit float, by default)\n",
    "x = torch.ones(4, 3)\n",
    "print (a, a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Create a zero tensor using integers\n",
    "a = torch.zeros(4, 3,  dtype=torch.int64)\n",
    "print (a, a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  2,  4],\n",
      "        [ 6,  8, 10],\n",
      "        [12, 14, 16]])\n",
      "torch.int64\n",
      "\n",
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.],\n",
      "        [12., 14., 16.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Use PyTorch arange like NumPy arange:\n",
    "a = torch.arange(0, 18, 2).reshape(3,3)\n",
    "print (a)\n",
    "print (a.dtype)\n",
    "\n",
    "# Use decimals to create a float tensor\n",
    "a = torch.arange(0.0, 18.0, 2.0).reshape(3,3)\n",
    "print()\n",
    "print (a)\n",
    "print (a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "tensor([[ 0.,  2.,  4.,  6.],\n",
      "        [ 8., 10., 12., 14.],\n",
      "        [16., 18., 20., 22.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Or linspace:\n",
    "a = torch.linspace(0.0, 22.0, 12).reshape(3,4)\n",
    "print()\n",
    "print (a)\n",
    "print (a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0477, 0.5256, 0.5988],\n",
      "        [0.6072, 0.9047, 0.5129],\n",
      "        [0.5905, 0.7084, 0.9485],\n",
      "        [0.9110, 0.8052, 0.2731]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Uniform random distribution (0-1)\n",
    "a = torch.rand(4,3)\n",
    "print (a)\n",
    "print (a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3883,  0.7024, -0.3425],\n",
      "        [ 1.1361,  0.3308,  0.2970],\n",
      "        [-0.2772, -0.6546,  0.0425],\n",
      "        [-0.9947,  1.4162, -0.8947]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Normal standard distribution\n",
    "a = torch.randn(4,3)\n",
    "print (a)\n",
    "print (a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 3, 0, 3, 3],\n",
      "        [3, 3, 3, 1, 1],\n",
      "        [2, 1, 0, 2, 1],\n",
      "        [2, 0, 3, 1, 2],\n",
      "        [3, 3, 2, 2, 3]])\n",
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "# Normal integer\n",
    "a = torch.randint(low=0, high=4, size=(5,5))\n",
    "print (a)\n",
    "print (a.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8796,  1.1050, -0.3258, -0.5240, -0.7160],\n",
      "        [ 0.8189, -0.3603,  0.6720,  0.3699, -1.5484]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Use dimensions of another tensor and generate random numbers\n",
    "x = torch.zeros(2,5)\n",
    "a = torch.randn_like(x)\n",
    "print (a)\n",
    "print (a.dtype)\n",
    "\n",
    "# Similar methods are:\n",
    "# torch.zeros_like(input)\n",
    "# torch.ones_like(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829],\n",
      "        [0.9593, 0.3904, 0.6009]])\n"
     ]
    }
   ],
   "source": [
    "# Set random seed\n",
    "torch.manual_seed(42)\n",
    "a = torch.rand(2, 3)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing tensor data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0],\n",
      "        [0, 0, 0]]) torch.int64\n",
      "\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Create a zero tensor using integers\n",
    "a = torch.zeros(4, 3,  dtype=torch.int64)\n",
    "print (a, a.dtype)\n",
    "\n",
    "# Convert to 32 bit\n",
    "b = a.type(torch.float32)\n",
    "print ()\n",
    "print (b, b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Torch Tensor from NumPy array\n",
    "Note: NumPy works in 64 bit precision by default, but we usally work in 32 bit in PyTorch (for efficiency).\n",
    "\n",
    "Additionally to the methods below, the `torch.from_numpy` method creates a link between a NumPy array and a Torch Tensor, such that if one is changed, so is the other. Usually though, we wish to have them as separate entities, with the Torch Tensor being a copy of the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create from numpy array\n",
    "# Define dtype in NumPy: note default NumPy array is 64 bit\n",
    "n = np.zeros(shape=(3,2))\n",
    "b = torch.tensor(n)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define NumPy array as 32 bit first\n",
    "n = np.zeros(shape=(3,2), dtype=np.float32)\n",
    "b = torch.tensor(n)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or change Torch tensor to 32 bit\n",
    "n = np.zeros(shape=(3,2))\n",
    "b = torch.tensor(n, dtype=torch.float32)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get tensor values as NumPy arrays use `.numpy()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0.],\n",
       "       [0., 0.],\n",
       "       [0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`torch.tensor` (lower case t in tensort) infers the data type from the original object. `torch.Tensor` (upper case T in Tensor) is an alias for `torch.FloatTensor` and will create a 32 bit floating point tensor object. \n",
    "\n",
    "See the example below, passing first an integer array to Torc, and then a 64 bit NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3]) torch.int64\n",
      "tensor([1., 2., 3.]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "n = np.array([1,2,3])\n",
    "a = torch.tensor(n)\n",
    "b = torch.Tensor(n)\n",
    "\n",
    "print (a, a.dtype)\n",
    "print (b, b.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.4714, 0.5480, 0.2013], dtype=torch.float64) torch.float64\n",
      "tensor([0.4714, 0.5480, 0.2013]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "n = np.random.random(3)\n",
    "a = torch.tensor(n)\n",
    "b = torch.Tensor(n)\n",
    "\n",
    "print (a, a.dtype)\n",
    "print (b, b.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scalar tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = a.sum()\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `.item` to get scalr tensor value as ordinary python sclalar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n",
      "torch.Size([4, 3])\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros(4, 3)\n",
    "\n",
    "print (a.dtype)\n",
    "print (a.shape)\n",
    "print (a.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensor operations\n",
    "\n",
    "See all operations at https://pytorch.org/docs/stable/index.html.\n",
    "\n",
    "Inplace operations are followed by `_` and work on the tensor itslef, rather than producing a copy. This is usually more efficient.\n",
    "\n",
    "Pytorch has many functions that parallel NumPy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Arithmetic</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>a + b</td><td>a.add(b)</td><td>element wise addition</td></tr>\n",
    "<tr><td>a - b</td><td>a.sub(b)</td><td>subtraction</td></tr>\n",
    "<tr><td>a * b</td><td>a.mul(b)</td><td>multiplication</td></tr>\n",
    "<tr><td>a / b</td><td>a.div(b)</td><td>division</td></tr>\n",
    "<tr><td>a % b</td><td>a.fmod(b)</td><td>modulo (remainder after division)</td></tr>\n",
    "<tr><td>a<sup>b</sup></td><td>a.pow(b)</td><td>power</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Monomial Operations</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>|a|</td><td>torch.abs(a)</td><td>absolute value</td></tr>\n",
    "<tr><td>1/a</td><td>torch.reciprocal(a)</td><td>reciprocal</td></tr>\n",
    "<tr><td>$\\sqrt{a}$</td><td>torch.sqrt(a)</td><td>square root</td></tr>\n",
    "<tr><td>log(a)</td><td>torch.log(a)</td><td>natural log</td></tr>\n",
    "<tr><td>e<sup>a</sup></td><td>torch.exp(a)</td><td>exponential</td></tr>\n",
    "<tr><td>12.34  ==>  12.</td><td>torch.trunc(a)</td><td>truncated integer</td></tr>\n",
    "<tr><td>12.34  ==>  0.34</td><td>torch.frac(a)</td><td>fractional component</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"display: inline-block\">\n",
    "<caption style=\"text-align: center\"><strong>Summary Statistics</strong></caption>\n",
    "<tr><th>OPERATION</th><th>FUNCTION</th><th>DESCRIPTION</th></tr>\n",
    "<tr><td>$\\sum a$</td><td>torch.sum(a)</td><td>sum</td></tr>\n",
    "<tr><td>$\\bar a$</td><td>torch.mean(a)</td><td>mean</td></tr>\n",
    "<tr><td>a<sub>max</sub></td><td>torch.max(a)</td><td>maximum</td></tr>\n",
    "<tr><td>a<sub>min</sub></td><td>torch.min(a)</td><td>minimum</td></tr>\n",
    "<tr><td colspan=\"3\">torch.max(a,b) returns a tensor of size a<br>containing the element wise max between a and b</td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dot products\n",
    "A <a href='https://en.wikipedia.org/wiki/Dot_product'>dot product</a> is the sum of the products of the corresponding entries of two 1D tensors. If the tensors are both vectors, the dot product is given as:<br>\n",
    "\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d & e & f \\end{bmatrix} = ad + be + cf$\n",
    "\n",
    "If the tensors include a column vector, then the dot product is the sum of the result of the multiplied matrices. For example:<br>\n",
    "$\\begin{bmatrix} a & b & c \\end{bmatrix} \\;\\cdot\\; \\begin{bmatrix} d \\\\ e \\\\ f \\end{bmatrix} = ad + be + cf$<br><br>\n",
    "Dot products can be expressed as <a href='https://pytorch.org/docs/stable/torch.html#torch.dot'><strong><tt>torch.dot(a,b)</tt></strong></a> or `a.dot(b)` or `b.dot(a)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 4., 10., 18.])\n",
      "\n",
      "tensor(32.)\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1,2,3], dtype=torch.float)\n",
    "b = torch.tensor([4,5,6], dtype=torch.float)\n",
    "print(a.mul(b)) # for reference\n",
    "print()\n",
    "print(a.dot(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\"><strong>NOTE:</strong> There's a slight difference between <tt>torch.dot()</tt> and <tt>numpy.dot()</tt>. While <tt>torch.dot()</tt> only accepts 1D arguments and returns a dot product, <tt>numpy.dot()</tt> also accepts 2D arguments and performs matrix multiplication. We show matrix multiplication below.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication\n",
    "2D <a href='https://en.wikipedia.org/wiki/Matrix_multiplication'>Matrix multiplication</a> is possible when the number of columns in tensor <strong><tt>A</tt></strong> matches the number of rows in tensor <strong><tt>B</tt></strong>. In this case, the product of tensor <strong><tt>A</tt></strong> with size $(x,y)$ and tensor <strong><tt>B</tt></strong> with size $(y,z)$ results in a tensor of size $(x,z)$\n",
    "<div>\n",
    "<div align=\"left\"><img src='./Images/Matrix_multiplication_diagram.png' align=\"left\"><br><br>\n",
    "\n",
    "$\\begin{bmatrix} a & b & c \\\\\n",
    "d & e & f \\end{bmatrix} \\;\\times\\; \\begin{bmatrix} m & n \\\\ p & q \\\\ r & s \\end{bmatrix} = \\begin{bmatrix} (am+bp+cr) & (an+bq+cs) \\\\\n",
    "(dm+ep+fr) & (dn+eq+fs) \\end{bmatrix}$</div></div>\n",
    "\n",
    "<div style=\"clear:both\">Image source: <a href='https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg'>https://commons.wikimedia.org/wiki/File:Matrix_multiplication_diagram_2.svg</a></div>\n",
    "\n",
    "Matrix multiplication can be computed using <a href='https://pytorch.org/docs/stable/torch.html#torch.mm'><strong><tt>torch.mm(a,b)</tt></strong></a> or `a.mm(b)` or `a @ b`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a:  torch.Size([2, 3])\n",
      "b:  torch.Size([3, 2])\n",
      "a x b:  torch.Size([2, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[0,2,4],[1,3,5]], dtype=torch.float)\n",
    "b = torch.tensor([[6,7],[8,9],[10,11]], dtype=torch.float)\n",
    "\n",
    "print('a: ',a.size())\n",
    "print('b: ',b.size())\n",
    "print('a x b: ',torch.mm(a,b).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.mm(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "# Or (the same)\n",
    "\n",
    "print(a.mm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[56., 62.],\n",
      "        [80., 89.]])\n"
     ]
    }
   ],
   "source": [
    "# Or (the same, but a bit obscure shorthand)\n",
    "\n",
    "print(a @ b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU tensors\n",
    "\n",
    "Tensors may be passed to/from GPUs using `cuda` device.\n",
    "\n",
    "See https://pytorch.org/docs/stable/notes/cuda.html\n",
    "\n",
    "By default, tensors are created on the CPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.FloatTensor(3,2)\n",
    "\n",
    "# Pass to GPU if one exists (and PyTorch is enables to use GPUs)\n",
    "try:\n",
    "    a = a.cuda()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "a.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexing and slicing\n",
    "\n",
    "Indexing and slicing works like NumPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(6).reshape(3,2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 3, 5])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the right hand column values\n",
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [3],\n",
       "        [5]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grabbing the right hand column as a (3,1) slice\n",
    "x[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshape with view and reshape\n",
    "\n",
    "View and reshape are essentially the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(10)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.reshape(2,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By passing in <tt>-1</tt> PyTorch will infer the correct value from the given tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(2,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(-1,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adopt another Tensors shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3, 4],\n",
       "        [5, 6, 7, 8, 9]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(2,5)\n",
    "x.view_as(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural net building blocks\n",
    "\n",
    "The `torch.nn` package contains lots of basic building blocks.\n",
    "Example of building sequential ANN:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1021, 0.1021, 0.1021, 0.0779, 0.1021, 0.1222, 0.0988, 0.0882, 0.1021,\n",
       "         0.1021]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "# Three layer nn ending in Softmax across dimension 1\n",
    "\n",
    "s = nn.Sequential(\n",
    "    nn.Linear(2, 5),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(5,20),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(20,10),\n",
    "    nn.Dropout(p=0.3),\n",
    "    nn.Softmax(dim=1)\n",
    ")\n",
    "\n",
    "s(torch.FloatTensor([[1,2]]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch modules\n",
    "\n",
    "We can create our own building clocks with the `nn.Module` class. This class also allows easy handling of the whole network (e.g. getting all parameters across the net)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OurModule(\n",
      "  (pipe): Sequential(\n",
      "    (0): Linear(in_features=2, out_features=5, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=5, out_features=20, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=20, out_features=3, bias=True)\n",
      "    (5): Dropout(p=0.3, inplace=False)\n",
      "    (6): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "tensor([[0.4366, 0.3595, 0.2039]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "class OurModule(nn.Module):\n",
    "    def __init__(self, num_inputs, num_classes, dropout_prob=0.3):\n",
    "        super(OurModule, self).__init__()\n",
    "        self.pipe = s = nn.Sequential(\n",
    "                            nn.Linear(num_inputs, 5),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(5,20),\n",
    "                            nn.ReLU(),\n",
    "                            nn.Linear(20,num_classes),\n",
    "                            nn.Dropout(p=0.3),\n",
    "                            nn.Softmax(dim=1)\n",
    "                            )\n",
    "            \n",
    "    # Modify the classess forward method\n",
    "    def forward(self,x):\n",
    "        return self.pipe(x)\n",
    "    \n",
    "net = OurModule(num_inputs=2, num_classes=3)\n",
    "v = torch.FloatTensor([[2,3]])\n",
    "out = net(v)\n",
    "print(net)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss functions\n",
    "\n",
    "Loss functions usually accept two arguments: prediction and observed.\n",
    "\n",
    "Most common loss functions are:\n",
    "\n",
    "* `nn.MSELoss`: mean square error (regression)\n",
    "* `nn.BCELoss` and `nn.BCEWithLogits`: Binary cross entropy (binary classification). With logits applies sigmoid transormation itslef and is usually more stable. Without logits expects a single probability value (i.e. sigmoid already done).\n",
    "* `nn.CrossEntropyLoss` and `NLLLoss`: Multiclass maximum likelyhood. First version applies LogSoftmax internally, while the second expects log proabilities as the input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizers\n",
    "\n",
    "Commonly used optimizers are:\n",
    "\n",
    "* `SGD`: vanilla stochastic gradient descent\n",
    "* `RMSpropr`: Hinton's optimizer\n",
    "* `Adagrad`: Adaptive gradiants optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blue print of a training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# Loop that iterates over data creating X and y batches\n",
    "for batch_samples, batch_labels in iterate_batches(data, batch_size=32):\n",
    "    # Create tensors from batch X and y\n",
    "    batch_samples_t = torch.tensor(batch_samples)\n",
    "    batch_labels_t = torch.tensor(batch_labels)\n",
    "    # Caluclate output of net\n",
    "    out_t = net(batch_samples_t)\n",
    "    # Calculate loss\n",
    "    loss_t = loss_function(out_t, batch_labels_t)\n",
    "    # Back propogate loss and calulcate gradients\n",
    "    loss_t.backward()\n",
    "    # Apply optimizer\n",
    "    optimizer.step()\n",
    "    # Reset network gradients (can also be done at start of loop)\n",
    "    optimizer.zero_grad()\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
